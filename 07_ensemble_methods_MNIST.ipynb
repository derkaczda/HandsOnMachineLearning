{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods\n",
    "\n",
    "This notebook is based on the topics in chapter 7. <br>\n",
    "We will answer the exercises 8 and 9 for the MNIST dataset <br>\n",
    "\n",
    "## General preparations\n",
    "### 1.1 Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test/Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train = mnist['data'][:60000], mnist['target'][:60000].astype(np.uint8)\n",
    "X_test, y_test = mnist['data'][60000:], mnist['target'][60000:].astype(np.uint8)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (48000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 784), (12000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('std_scaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exercise 8: Ensemble classification\n",
    "\n",
    "Load the MNIST data and split it into a training set, a validation set, and a test set. Then train various classifiers, such as a Random Forest classifier, an Extra-Trees classifier, and an SVM classifier. Next, try to compbine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting. Once you have found one, try it on the test set. How much bettere does it perform compared to the individual classifiers? <br><br>\n",
    "\n",
    "\n",
    "### 2.1 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('std_scaler', StandardScaler())])),\n",
       "                ('classifier', SVC(probability=True))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_classifier = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "svc_pipeline = Pipeline(\n",
    "    steps= [\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', svc_classifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "svc_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score on validation set is 0.9635\n"
     ]
    }
   ],
   "source": [
    "score = svc_pipeline.score(X_val, y_val)\n",
    "print(f\"SVC score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_svc_base_mnist.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models/\", exist_ok=True)\n",
    "\n",
    "joblib.dump(svc_classifier, 'models/07_svc_base_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        Pipeline(steps=[('std_scaler',\n",
       "                                                         StandardScaler())])),\n",
       "                                       ('classifier', SVC(probability=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__C': [1, 0.1, 1.5],\n",
       "                         'classifier__kernel': ['rbf', 'sigmoid'],\n",
       "                         'classifier__probability': [True]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_params_grid = {\n",
    "    'classifier__kernel': ['rbf', 'sigmoid'],\n",
    "    'classifier__C':[1, 0.1, 1.5],\n",
    "    'classifier__probability': [True]\n",
    "}\n",
    "\n",
    "svc_grid_search = GridSearchCV(svc_pipeline, svc_params_grid, cv=3, return_train_score=True, n_jobs=-1)\n",
    "svc_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_svc_search_mnist.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svc_grid_search.best_estimator_, 'models/07_svc_search_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score on validation set is 0.9659166666666666\n"
     ]
    }
   ],
   "source": [
    "score = svc_grid_search.best_estimator_.score(X_val, y_val)\n",
    "print(f\"SVC score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 1.5,\n",
       " 'classifier__kernel': 'rbf',\n",
       " 'classifier__probability': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('std_scaler', StandardScaler())])),\n",
       "                ('classifier', SVC(C=1.5, probability=True))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_classifier = SVC(kernel='rbf', C=1.5, probability=True)\n",
    "\n",
    "svc_pipeline = Pipeline(\n",
    "    steps= [\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', svc_classifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "svc_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score on validation set is 0.9659166666666666\n"
     ]
    }
   ],
   "source": [
    "score = svc_pipeline.score(X_val, y_val)\n",
    "print(f\"SVC score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(svc_grid_search.best_estimator_, 'models/07_svc_after_search_mnist.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('std_scaler', StandardScaler())])),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_classifier = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "forest_pipeline = Pipeline(\n",
    "    steps= [\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', forest_classifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "forest_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest score on validation set is 0.9694166666666667\n"
     ]
    }
   ],
   "source": [
    "score = forest_pipeline.score(X_val, y_val)\n",
    "print(f\"Random forest score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_forest_base_mnist.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(forest_classifier, 'models/07_forest_base_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_forest_search_mnist.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "forest_params_grid = {\n",
    "    'classifier__n_estimators': [500, 600, 1000],\n",
    "    'classifier__max_depth':[20, 30, 40],\n",
    "    'classifier__min_samples_leaf':[2, 5],\n",
    "    'classifier__n_jobs':[-1],\n",
    "    'classifier__random_state':[42]\n",
    "}\n",
    "\n",
    "forest_grid_search = GridSearchCV(forest_pipeline, forest_params_grid, cv=3, return_train_score=True, n_jobs=-1)\n",
    "forest_grid_search.fit(X_train, y_train)\n",
    "joblib.dump(forest_grid_search.best_estimator_, 'models/07_forest_search_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest score score on validation set is 0.9681666666666666\n"
     ]
    }
   ],
   "source": [
    "score = forest_grid_search.best_estimator_.score(X_val, y_val)\n",
    "print(f\"Forest score score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 40,\n",
       " 'classifier__min_samples_leaf': 2,\n",
       " 'classifier__n_estimators': 1000,\n",
       " 'classifier__n_jobs': -1,\n",
       " 'classifier__random_state': 42}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('std_scaler', StandardScaler())])),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_depth=40, min_samples_leaf=2,\n",
       "                                        n_estimators=1000, n_jobs=-1,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_classifier = RandomForestClassifier(n_estimators=1000, min_samples_leaf=2,\n",
    "                                           max_depth=40, random_state=42, n_jobs=-1)\n",
    "\n",
    "forest_pipeline = Pipeline(\n",
    "    steps= [\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', forest_classifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "forest_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest score on validation set is 0.9681666666666666\n"
     ]
    }
   ],
   "source": [
    "score = forest_pipeline.score(X_val, y_val)\n",
    "print(f\"Random forest score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_forest_after_search_mnist.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(forest_classifier, 'models/07_forest_after_search_mnist.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extremely random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_extra_forest_base_mnist.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import joblib\n",
    "\n",
    "extra_forest_classifier = ExtraTreesClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "extra_forest_pipeline = Pipeline(\n",
    "    steps= [\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', extra_forest_classifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "extra_forest_pipeline.fit(X_train, y_train)\n",
    "joblib.dump(extra_forest_classifier, 'models/07_extra_forest_base_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra trees score on validation set is 0.97225\n"
     ]
    }
   ],
   "source": [
    "score = extra_forest_pipeline.score(X_val, y_val)\n",
    "print(f\"Extra trees score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_extra_forest_search_mnist.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "extra_forest_params_grid = {\n",
    "    'classifier__n_estimators': [500, 600, 1000],\n",
    "    'classifier__max_depth':[20, 30, 40],\n",
    "    'classifier__min_samples_leaf':[2, 5],\n",
    "    'classifier__n_jobs':[-1],\n",
    "    'classifier__random_state':[42]\n",
    "}\n",
    "\n",
    "extra_forest_grid_search = GridSearchCV(extra_forest_pipeline, extra_forest_params_grid, cv=3, return_train_score=True, n_jobs=-1)\n",
    "extra_forest_grid_search.fit(X_train, y_train)\n",
    "joblib.dump(extra_forest_grid_search.best_estimator_, 'models/07_extra_forest_search_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest score score on validation set is 0.9701666666666666\n"
     ]
    }
   ],
   "source": [
    "score = extra_forest_grid_search.best_estimator_.score(X_val, y_val)\n",
    "print(f\"Forest score score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 40,\n",
       " 'classifier__min_samples_leaf': 2,\n",
       " 'classifier__n_estimators': 1000,\n",
       " 'classifier__n_jobs': -1,\n",
       " 'classifier__random_state': 42}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_forest_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_extra_forest_after_search_mnist.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_forest_classifier = ExtraTreesClassifier(random_state=42, max_depth=40, \n",
    "                                               min_samples_leaf=2, n_estimators=1000,\n",
    "                                               n_jobs=-1)\n",
    "\n",
    "extra_forest_pipeline = Pipeline(\n",
    "    steps= [\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', extra_forest_classifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "extra_forest_pipeline.fit(X_train, y_train)\n",
    "joblib.dump(extra_forest_classifier, 'models/07_extra_forest_after_search_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra trees score on validation set is 0.9701666666666666\n"
     ]
    }
   ],
   "source": [
    "score = extra_forest_pipeline.score(X_val, y_val)\n",
    "print(f\"Extra trees score on validation set is {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Putting it all together into a ensemble\n",
    "\n",
    "#### 2.4.1 Hard Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "svc_model = SVC(kernel='rbf', C=1.5, probability=True)\n",
    "random_forest_model = RandomForestClassifier(n_estimators=1000, min_samples_leaf=2,\n",
    "                                           max_depth=40, random_state=42, n_jobs=-1)\n",
    "extra_trees_model = ExtraTreesClassifier(random_state=42, max_depth=40, \n",
    "                                               min_samples_leaf=2, n_estimators=1000,\n",
    "                                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/07_ensemble_classifier_mnist.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "\n",
    "ensemble_classifier = VotingClassifier(\n",
    "    estimators=[('svc',svc_model), ('forest',random_forest_model), ('extra_trees',extra_trees_model)],\n",
    "    voting='hard',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ensemble_pipeline = Pipeline(\n",
    "    steps= [\n",
    "        ('preprocessing', preprocessing_pipeline),\n",
    "        ('classifier', ensemble_classifier)\n",
    "    ]\n",
    ")\n",
    "\n",
    "ensemble_pipeline.fit(X_train, y_train)\n",
    "joblib.dump(ensemble_classifier, 'models/07_ensemble_classifier_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ensemble scored 0.9708333333333333\n"
     ]
    }
   ],
   "source": [
    "score = ensemble_pipeline.score(X_val, y_val)\n",
    "print(f\"The ensemble scored {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 scoring on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ensemble scored 0.9712; SVC 0.9663; Forest 0.968; Extra trees 0.9703\n"
     ]
    }
   ],
   "source": [
    "X_test_trans = preprocessing_pipeline.transform(X_test)\n",
    "score_ensemble = ensemble_classifier.score(X_test_trans, y_test)\n",
    "score_svc = ensemble_classifier.named_estimators_['svc'].score(X_test_trans,y_test)\n",
    "score_forest = ensemble_classifier.named_estimators_['forest'].score(X_test_trans, y_test)\n",
    "score_extra = ensemble_classifier.named_estimators_['extra_trees'].score(X_test_trans, y_test)\n",
    "print(f\"The ensemble scored {score_ensemble}; SVC {score_svc}; Forest {score_forest}; Extra trees {score_extra}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exercise 9: Blender\n",
    "\n",
    "Run the individual classifiers from the previous exercise to make predictions on the valdiation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions form all your classifiers for an image, and the target is the image's class. Train a classifier on this new training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "svc_model = joblib.load('models/07_svc_after_search_mnist.pkl')\n",
    "forest_model = joblib.load('models/07_forest_after_search_mnist.pkl')\n",
    "extra_model = joblib.load('models/07_extra_forest_after_search_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_val_transformed = preprocessing_pipeline.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_predictions = svc_model.predict(X_val_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_predictions = forest_model.predict(X_val_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_predictions = extra_model.predict(X_val_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 8, ..., 9, 7, 2], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 8, ..., 9, 7, 2], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 8, ..., 9, 7, 2], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated = np.concatenate([svc_predictions,forest_predictions], axis=0)\n",
    "concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 7, 7],\n",
       "       [3, 3, 3],\n",
       "       [8, 8, 8],\n",
       "       ...,\n",
       "       [9, 9, 9],\n",
       "       [7, 7, 7],\n",
       "       [2, 2, 2]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = np.column_stack((svc_predictions, forest_predictions, extra_predictions))\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 9 7]\n",
      "[0 2 2]\n",
      "[6 8 6]\n",
      "[9 1 1]\n",
      "[4 9 9]\n",
      "[3 5 3]\n",
      "[1 8 1]\n",
      "[4 9 9]\n",
      "[4 9 9]\n",
      "[9 2 9]\n",
      "[6 0 0]\n",
      "[0 5 8]\n",
      "[4 4 9]\n",
      "[8 8 5]\n",
      "[7 1 7]\n",
      "[9 8 9]\n",
      "[6 5 5]\n",
      "[7 1 1]\n",
      "[9 8 7]\n",
      "[5 8 8]\n",
      "[0 8 8]\n",
      "[0 5 0]\n",
      "[9 3 9]\n",
      "[2 2 7]\n",
      "[9 4 4]\n",
      "[7 1 1]\n",
      "[9 2 2]\n",
      "[4 6 6]\n",
      "[6 2 2]\n",
      "[7 9 9]\n",
      "[0 8 6]\n",
      "[2 8 8]\n",
      "[8 3 3]\n",
      "[3 5 5]\n",
      "[5 0 0]\n",
      "[7 9 9]\n",
      "[6 5 6]\n",
      "[2 7 7]\n",
      "[1 8 1]\n",
      "[4 6 6]\n",
      "[8 3 3]\n",
      "[2 6 6]\n",
      "[9 0 0]\n",
      "[2 3 3]\n",
      "[7 3 7]\n",
      "[9 8 9]\n",
      "[7 1 7]\n",
      "[7 2 7]\n",
      "[7 4 4]\n",
      "[3 0 5]\n",
      "[7 0 9]\n",
      "[7 2 7]\n",
      "[7 2 7]\n",
      "[2 8 8]\n",
      "[7 2 2]\n",
      "[8 2 2]\n",
      "[5 8 5]\n",
      "[9 4 9]\n",
      "[9 8 9]\n",
      "[3 5 3]\n",
      "[9 4 4]\n",
      "[7 3 3]\n",
      "[7 2 7]\n",
      "[9 8 9]\n",
      "[9 3 3]\n",
      "[4 2 4]\n",
      "[3 2 2]\n",
      "[6 4 6]\n",
      "[1 6 4]\n",
      "[6 2 2]\n",
      "[8 8 3]\n",
      "[9 4 4]\n",
      "[2 8 8]\n",
      "[2 7 7]\n",
      "[8 2 2]\n",
      "[1 8 1]\n",
      "[0 8 6]\n",
      "[3 2 2]\n",
      "[2 2 7]\n",
      "[7 8 8]\n",
      "[3 3 5]\n",
      "[9 4 4]\n",
      "[9 5 9]\n",
      "[5 8 9]\n",
      "[2 8 8]\n",
      "[3 3 8]\n",
      "[2 8 8]\n",
      "[7 2 7]\n",
      "[7 2 2]\n",
      "[9 5 9]\n",
      "[5 3 3]\n",
      "[8 8 9]\n",
      "[7 9 7]\n",
      "[0 2 2]\n",
      "[7 4 4]\n",
      "[6 3 3]\n",
      "[6 8 8]\n",
      "[6 8 6]\n",
      "[9 5 9]\n",
      "[4 8 4]\n",
      "[0 8 0]\n",
      "[8 8 5]\n",
      "[9 5 9]\n",
      "[7 2 1]\n",
      "[3 5 5]\n",
      "[0 8 0]\n",
      "[7 2 2]\n",
      "[3 5 5]\n",
      "[7 2 7]\n",
      "[7 9 9]\n",
      "[7 2 7]\n",
      "[4 4 9]\n",
      "[8 8 9]\n",
      "[3 2 3]\n",
      "[7 6 6]\n",
      "[9 3 3]\n",
      "[4 3 9]\n",
      "[3 5 3]\n",
      "[7 4 4]\n",
      "[6 0 0]\n",
      "[3 5 5]\n",
      "[4 8 4]\n",
      "[7 3 3]\n",
      "[9 8 8]\n",
      "[3 0 0]\n",
      "[5 5 4]\n",
      "[0 5 6]\n",
      "[6 4 4]\n",
      "[4 9 9]\n",
      "[7 2 7]\n",
      "[0 0 6]\n",
      "[3 8 9]\n",
      "[9 0 0]\n",
      "[3 8 8]\n",
      "[3 3 2]\n",
      "[8 2 2]\n",
      "[6 0 0]\n",
      "[3 3 9]\n",
      "[1 5 5]\n",
      "[5 8 8]\n",
      "[3 8 3]\n",
      "[5 8 9]\n",
      "[7 9 9]\n",
      "[2 6 6]\n",
      "[8 8 9]\n",
      "[1 3 1]\n",
      "[4 0 0]\n",
      "[5 8 5]\n",
      "[5 8 8]\n",
      "[7 9 9]\n",
      "[3 2 2]\n",
      "[9 8 8]\n",
      "[1 5 4]\n",
      "[2 1 1]\n",
      "[7 2 3]\n",
      "[2 3 3]\n",
      "[9 4 4]\n",
      "[7 1 1]\n",
      "[2 0 0]\n",
      "[9 4 4]\n",
      "[2 0 2]\n",
      "[9 8 8]\n",
      "[9 9 4]\n",
      "[2 4 4]\n",
      "[7 2 7]\n",
      "[9 3 9]\n",
      "[4 4 9]\n",
      "[3 2 2]\n",
      "[7 4 4]\n",
      "[3 8 3]\n",
      "[8 2 2]\n",
      "[5 0 0]\n",
      "[9 7 9]\n",
      "[5 3 3]\n",
      "[7 9 9]\n",
      "[7 6 6]\n",
      "[4 7 7]\n",
      "[9 8 8]\n",
      "[7 8 7]\n",
      "[7 6 6]\n",
      "[7 6 6]\n",
      "[7 9 9]\n",
      "[5 6 6]\n",
      "[2 4 4]\n",
      "[2 4 4]\n",
      "[6 0 0]\n",
      "[3 5 3]\n",
      "[7 9 9]\n",
      "[9 7 7]\n",
      "[3 2 2]\n",
      "[9 3 3]\n",
      "[4 4 9]\n",
      "[7 4 4]\n",
      "[0 8 0]\n",
      "[5 8 8]\n",
      "[2 1 1]\n",
      "[7 0 0]\n",
      "[7 6 6]\n",
      "[4 9 9]\n",
      "[9 8 9]\n",
      "[4 2 2]\n",
      "[4 3 4]\n",
      "[7 0 7]\n",
      "[7 3 7]\n",
      "[7 8 8]\n",
      "[9 5 9]\n",
      "[7 8 7]\n",
      "[7 6 6]\n",
      "[7 9 7]\n",
      "[4 2 2]\n",
      "[3 5 3]\n",
      "[4 6 4]\n",
      "[2 0 0]\n",
      "[4 9 9]\n",
      "[6 4 4]\n",
      "[7 5 5]\n",
      "[1 8 1]\n",
      "[9 3 9]\n",
      "[8 0 8]\n",
      "[3 8 8]\n",
      "[5 3 5]\n",
      "[6 0 0]\n",
      "[8 3 3]\n",
      "[9 8 8]\n",
      "[7 0 0]\n",
      "[7 3 3]\n",
      "[7 8 8]\n",
      "[7 1 1]\n",
      "[7 4 4]\n",
      "[2 6 6]\n",
      "[9 4 4]\n",
      "[6 2 2]\n",
      "[8 3 3]\n",
      "[7 2 2]\n",
      "[8 8 5]\n",
      "[7 3 3]\n",
      "[8 4 4]\n",
      "[3 7 7]\n",
      "[3 5 5]\n",
      "[7 9 9]\n",
      "[9 4 9]\n",
      "[2 1 1]\n",
      "[3 5 3]\n",
      "[7 4 4]\n",
      "[4 4 7]\n",
      "[4 4 9]\n",
      "[2 2 8]\n",
      "[4 9 9]\n",
      "[9 5 9]\n",
      "[7 6 6]\n",
      "[3 2 2]\n",
      "[9 7 7]\n",
      "[9 4 9]\n",
      "[8 8 1]\n",
      "[9 8 8]\n",
      "[7 8 8]\n",
      "[6 0 0]\n",
      "[3 3 9]\n",
      "[7 3 7]\n",
      "[3 2 2]\n",
      "[4 5 4]\n",
      "[7 8 8]\n",
      "[4 5 9]\n",
      "[1 2 2]\n",
      "[1 2 1]\n",
      "[2 2 7]\n",
      "[9 7 7]\n",
      "[7 3 7]\n",
      "[9 5 9]\n",
      "[7 4 9]\n",
      "[0 3 3]\n",
      "[5 6 6]\n",
      "[6 0 0]\n",
      "[3 2 2]\n",
      "[9 3 9]\n",
      "[4 6 4]\n",
      "[7 3 7]\n",
      "[7 2 2]\n",
      "[9 4 4]\n",
      "[2 1 1]\n",
      "[3 5 5]\n",
      "[2 0 6]\n",
      "[2 7 7]\n",
      "[2 2 5]\n",
      "[0 8 8]\n",
      "[8 2 8]\n",
      "[2 6 2]\n",
      "[3 8 3]\n",
      "[7 2 7]\n",
      "[7 2 2]\n",
      "[8 5 7]\n",
      "[7 8 8]\n",
      "[0 8 0]\n",
      "[4 6 4]\n",
      "[3 6 6]\n",
      "[9 3 9]\n",
      "[3 8 8]\n",
      "[1 2 1]\n",
      "[6 8 6]\n",
      "[4 5 5]\n",
      "[3 2 3]\n",
      "[9 4 7]\n",
      "[7 6 6]\n",
      "[7 5 5]\n",
      "[3 9 7]\n",
      "[7 9 9]\n",
      "[7 3 9]\n",
      "[9 2 9]\n",
      "[3 2 2]\n",
      "[4 2 2]\n",
      "[6 0 2]\n",
      "[7 2 7]\n",
      "[2 3 3]\n",
      "[7 3 3]\n",
      "[8 3 3]\n",
      "[3 2 2]\n",
      "[8 8 0]\n",
      "[1 2 2]\n",
      "[5 8 8]\n",
      "[3 5 5]\n",
      "[8 8 5]\n",
      "[7 6 6]\n",
      "[7 9 9]\n",
      "[7 8 7]\n",
      "[7 2 2]\n",
      "[3 3 7]\n",
      "[9 3 9]\n",
      "[8 3 4]\n",
      "[9 4 9]\n",
      "[1 2 1]\n",
      "[2 6 6]\n",
      "[7 8 7]\n",
      "[9 3 9]\n",
      "[3 2 2]\n",
      "[0 0 6]\n",
      "[9 0 9]\n",
      "[7 2 7]\n",
      "[9 5 5]\n",
      "[8 5 5]\n",
      "[8 8 9]\n",
      "[3 2 2]\n",
      "[5 6 5]\n",
      "[3 2 2]\n",
      "[2 2 1]\n",
      "[2 4 4]\n",
      "[6 0 6]\n",
      "[9 8 8]\n",
      "[2 3 3]\n",
      "[5 8 5]\n",
      "[5 8 8]\n",
      "[7 4 4]\n",
      "[3 8 3]\n",
      "[0 0 7]\n",
      "[3 8 8]\n",
      "[2 4 4]\n",
      "[0 0 5]\n",
      "[1 2 2]\n",
      "[9 5 9]\n",
      "[4 8 4]\n",
      "[9 7 7]\n",
      "[9 3 3]\n",
      "[6 0 0]\n",
      "[7 6 6]\n",
      "[4 7 7]\n",
      "[9 7 7]\n",
      "[4 6 6]\n",
      "[4 5 4]\n",
      "[2 4 4]\n",
      "[7 9 9]\n",
      "[9 2 9]\n",
      "[1 6 6]\n",
      "[4 9 4]\n",
      "[0 0 6]\n",
      "[9 4 9]\n",
      "[2 2 1]\n",
      "[1 8 8]\n",
      "[7 9 9]\n",
      "[7 2 7]\n",
      "[7 1 7]\n",
      "[7 3 3]\n",
      "[4 8 4]\n",
      "[7 2 7]\n",
      "[6 5 5]\n",
      "[7 6 6]\n",
      "[3 8 3]\n",
      "[6 5 6]\n",
      "[4 2 9]\n",
      "[3 5 3]\n",
      "[6 5 5]\n",
      "[6 2 2]\n",
      "[1 3 3]\n",
      "[3 5 3]\n",
      "[2 5 5]\n",
      "[7 3 3]\n",
      "[4 6 6]\n",
      "[7 1 1]\n",
      "[9 7 7]\n",
      "[9 3 9]\n",
      "[7 8 8]\n",
      "[7 2 2]\n",
      "[9 3 3]\n",
      "[0 8 0]\n",
      "[8 5 5]\n",
      "[3 2 3]\n",
      "[2 4 4]\n",
      "[2 5 2]\n",
      "[3 2 2]\n",
      "[7 8 8]\n",
      "[6 4 6]\n",
      "[2 3 3]\n",
      "[2 6 6]\n",
      "[4 9 9]\n",
      "[4 7 7]\n",
      "[6 5 5]\n",
      "[7 2 2]\n",
      "[5 8 5]\n",
      "[3 7 7]\n",
      "[3 5 5]\n",
      "[8 3 3]\n",
      "[4 4 9]\n",
      "[2 2 1]\n",
      "[1 3 3]\n",
      "[5 0 0]\n",
      "[8 3 3]\n",
      "[2 0 0]\n",
      "[5 8 5]\n",
      "[8 2 2]\n",
      "[1 2 3]\n",
      "[6 8 8]\n",
      "[4 5 8]\n",
      "[5 8 8]\n",
      "[8 2 2]\n",
      "[7 6 6]\n",
      "[7 6 6]\n",
      "[3 7 9]\n",
      "[7 3 3]\n",
      "[7 2 2]\n",
      "[3 5 3]\n",
      "[7 2 2]\n",
      "[7 2 2]\n",
      "[3 5 5]\n",
      "[7 5 5]\n",
      "[9 0 9]\n",
      "[6 6 5]\n",
      "[5 5 8]\n",
      "[0 8 0]\n",
      "[2 8 8]\n",
      "[7 2 7]\n",
      "[9 0 9]\n",
      "[6 4 4]\n",
      "[7 4 4]\n",
      "[7 5 5]\n",
      "[7 2 7]\n",
      "[4 9 9]\n",
      "[5 8 8]\n",
      "[8 5 8]\n",
      "[5 8 8]\n",
      "[4 9 4]\n",
      "[6 5 6]\n",
      "[8 3 3]\n",
      "[7 2 2]\n",
      "[0 5 5]\n",
      "[5 2 2]\n",
      "[7 2 9]\n",
      "[5 0 0]\n",
      "[1 2 2]\n",
      "[2 0 0]\n",
      "[6 4 4]\n",
      "[4 4 9]\n",
      "[7 9 9]\n",
      "[7 5 7]\n",
      "[8 6 8]\n",
      "[9 7 7]\n",
      "[9 4 4]\n",
      "[1 3 1]\n",
      "[9 5 5]\n",
      "[9 4 9]\n",
      "[7 9 9]\n",
      "[9 3 8]\n",
      "[2 9 9]\n",
      "[8 8 9]\n",
      "[5 4 4]\n",
      "[7 3 7]\n",
      "[7 8 8]\n",
      "[8 4 4]\n",
      "[3 5 3]\n",
      "[3 8 9]\n",
      "[0 6 6]\n",
      "[5 0 5]\n",
      "[3 5 3]\n",
      "[5 3 5]\n",
      "[2 5 2]\n",
      "[7 5 9]\n",
      "[6 5 5]\n",
      "[2 7 7]\n",
      "[7 2 7]\n",
      "[7 3 3]\n",
      "[3 3 5]\n",
      "[7 9 9]\n",
      "[7 3 3]\n",
      "[4 8 7]\n",
      "[7 8 9]\n",
      "[9 5 9]\n",
      "[9 2 9]\n",
      "[7 0 7]\n",
      "[3 2 2]\n",
      "[7 9 9]\n",
      "[7 6 6]\n",
      "[9 2 2]\n",
      "[1 2 1]\n",
      "[5 8 8]\n",
      "[2 6 6]\n",
      "[7 0 0]\n",
      "[3 2 3]\n",
      "[4 6 6]\n",
      "[7 3 9]\n",
      "[2 0 0]\n",
      "[7 6 6]\n",
      "[8 8 5]\n",
      "[2 3 3]\n",
      "[9 5 9]\n",
      "[2 3 3]\n",
      "[9 4 9]\n",
      "[4 2 2]\n",
      "[9 3 3]\n",
      "[6 1 1]\n",
      "[6 5 5]\n",
      "[8 8 4]\n",
      "[8 8 9]\n",
      "[7 0 7]\n",
      "[6 8 6]\n",
      "[7 0 7]\n",
      "[1 2 1]\n",
      "[9 4 4]\n",
      "[5 3 3]\n",
      "[9 3 9]\n",
      "[7 2 7]\n",
      "[3 5 5]\n",
      "[9 3 3]\n",
      "[7 2 2]\n",
      "[7 4 4]\n",
      "[9 7 7]\n",
      "[7 3 3]\n",
      "[9 4 4]\n",
      "[2 6 6]\n",
      "[4 8 1]\n",
      "[8 2 2]\n",
      "[9 3 7]\n",
      "[5 8 5]\n",
      "[6 3 3]\n",
      "[3 3 8]\n",
      "[9 2 2]\n",
      "[8 2 8]\n",
      "[7 2 2]\n",
      "[9 3 9]\n",
      "[2 3 3]\n",
      "Count is 556 vs. total count 12000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for a in new_data:\n",
    "    if not np.all(a == a[0]):\n",
    "        count += 1\n",
    "        print(a)\n",
    "        \n",
    "print(f\"Count is {count} vs. total count {len(new_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dldz\\anaconda3\\envs\\handson\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "blender = MLPClassifier(random_state=42)\n",
    "blender.fit(new_data, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test_transformed = preprocessing_pipeline.transform(X_test)\n",
    "svc_test_pred = svc_model.predict(x_test_transformed)\n",
    "forest_test_pred = forest_model.predict(x_test_transformed)\n",
    "extra_test_pred = extra_model.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blender scored 0.9684\n"
     ]
    }
   ],
   "source": [
    "blender_score = blender.score(np.column_stack((svc_test_pred, forest_test_pred, extra_test_pred)), y_test)\n",
    "print(f\"Blender scored {blender_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
